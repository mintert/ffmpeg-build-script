diff --git a/libavdevice/avfoundation.m b/libavdevice/avfoundation.m
index 59d5b0af4f..74dddf4ad4 100644
--- a/libavdevice/avfoundation.m
+++ b/libavdevice/avfoundation.m
@@ -38,6 +38,8 @@
 #include "libavutil/imgutils.h"
 #include "avdevice.h"
 
+#define QUEUE_SIZE 400
+
 static const int avf_time_base = 1000000;
 
 static const AVRational avf_time_base_q = {
@@ -79,6 +81,11 @@ static const struct AVFPixelFormatSpec avf_pixel_formats[] = {
     { AV_PIX_FMT_NONE, 0 }
 };
 
+enum {
+    QUEUE_IS_EMPTY,
+    QUEUE_HAS_BUFFERS,
+};
+
 typedef struct
 {
     AVClass*        class;
@@ -87,7 +94,6 @@ typedef struct
     int             audio_frames_captured;
     int64_t         first_pts;
     int64_t         first_audio_pts;
-    pthread_mutex_t frame_lock;
     id              avf_delegate;
     id              avf_audio_delegate;
 
@@ -96,10 +102,6 @@ typedef struct
 
     int             capture_cursor;
     int             capture_mouse_clicks;
-    int             capture_raw_data;
-    int             drop_late_frames;
-    int             video_is_muxed;
-    int             video_is_screen;
 
     int             list_devices;
     int             video_device_index;
@@ -128,25 +130,12 @@ typedef struct
     AVCaptureSession         *capture_session;
     AVCaptureVideoDataOutput *video_output;
     AVCaptureAudioDataOutput *audio_output;
-    CMSampleBufferRef         current_frame;
-    CMSampleBufferRef         current_audio_frame;
 
-    AVCaptureDevice          *observed_device;
-#if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
-    AVCaptureDeviceTransportControlsPlaybackMode observed_mode;
-#endif
-    int                      observed_quit;
-} AVFContext;
+    NSConditionLock *lock;
+    NSMutableArray *video_queue;
+    NSMutableArray *audio_queue;
 
-static void lock_frames(AVFContext* ctx)
-{
-    pthread_mutex_lock(&ctx->frame_lock);
-}
-
-static void unlock_frames(AVFContext* ctx)
-{
-    pthread_mutex_unlock(&ctx->frame_lock);
-}
+} AVFContext;
 
 /** FrameReciever class - delegate for AVCaptureSession
  */
@@ -169,71 +158,27 @@ static void unlock_frames(AVFContext* ctx)
 {
     if (self = [super init]) {
         _context = context;
-
-        // start observing if a device is set for it
-#if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
-        if (_context->observed_device) {
-            NSString *keyPath = NSStringFromSelector(@selector(transportControlsPlaybackMode));
-            NSKeyValueObservingOptions options = NSKeyValueObservingOptionNew;
-
-            [_context->observed_device addObserver: self
-                                        forKeyPath: keyPath
-                                           options: options
-                                           context: _context];
-        }
-#endif
     }
     return self;
 }
 
-- (void)dealloc {
-    // stop observing if a device is set for it
-#if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
-    if (_context->observed_device) {
-        NSString *keyPath = NSStringFromSelector(@selector(transportControlsPlaybackMode));
-        [_context->observed_device removeObserver: self forKeyPath: keyPath];
-    }
-#endif
-    [super dealloc];
-}
-
-- (void)observeValueForKeyPath:(NSString *)keyPath
-                      ofObject:(id)object
-                        change:(NSDictionary *)change
-                       context:(void *)context {
-    if (context == _context) {
-#if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
-        AVCaptureDeviceTransportControlsPlaybackMode mode =
-            [change[NSKeyValueChangeNewKey] integerValue];
-
-        if (mode != _context->observed_mode) {
-            if (mode == AVCaptureDeviceTransportControlsNotPlayingMode) {
-                _context->observed_quit = 1;
-            }
-            _context->observed_mode = mode;
-        }
-#endif
-    } else {
-        [super observeValueForKeyPath: keyPath
-                             ofObject: object
-                               change: change
-                              context: context];
-    }
-}
-
 - (void)  captureOutput:(AVCaptureOutput *)captureOutput
   didOutputSampleBuffer:(CMSampleBufferRef)videoFrame
          fromConnection:(AVCaptureConnection *)connection
 {
-    lock_frames(_context);
+    NSMutableArray *queue = _context->video_queue;
+    NSConditionLock *lock = _context->lock;
+
+    [lock lock];
 
-    if (_context->current_frame != nil) {
-        CFRelease(_context->current_frame);
+    if ([queue count] == QUEUE_SIZE) {
+        av_log(_context, AV_LOG_WARNING, "video queue is full, the oldest frame has been dropped\n");
+        [queue removeLastObject];
     }
 
-    _context->current_frame = (CMSampleBufferRef)CFRetain(videoFrame);
+    [queue insertObject:(id)videoFrame atIndex:0];
 
-    unlock_frames(_context);
+    [lock unlockWithCondition:QUEUE_HAS_BUFFERS];
 
     ++_context->frames_captured;
 }
@@ -269,15 +214,19 @@ static void unlock_frames(AVFContext* ctx)
   didOutputSampleBuffer:(CMSampleBufferRef)audioFrame
          fromConnection:(AVCaptureConnection *)connection
 {
-    lock_frames(_context);
+    NSMutableArray *queue = _context->audio_queue;
+    NSConditionLock *lock = _context->lock;
 
-    if (_context->current_audio_frame != nil) {
-        CFRelease(_context->current_audio_frame);
+    [lock lock];
+
+    if ([queue count] == QUEUE_SIZE) {
+        av_log(_context, AV_LOG_WARNING, "audio queue is full, the oldest frame has been dropped\n");
+        [queue removeLastObject];
     }
 
-    _context->current_audio_frame = (CMSampleBufferRef)CFRetain(audioFrame);
+    [queue insertObject:(id)audioFrame atIndex:0];
 
-    unlock_frames(_context);
+    [lock unlockWithCondition:QUEUE_HAS_BUFFERS];
 
     ++_context->audio_frames_captured;
 }
@@ -302,11 +251,13 @@ static void destroy_context(AVFContext* ctx)
 
     av_freep(&ctx->audio_buffer);
 
-    pthread_mutex_destroy(&ctx->frame_lock);
+    [ctx->audio_queue release];
+    [ctx->video_queue release];
+    [ctx->lock release];
 
-    if (ctx->current_frame) {
-        CFRelease(ctx->current_frame);
-    }
+    ctx->audio_queue = NULL;
+    ctx->video_queue = NULL;
+    ctx->lock = NULL;
 }
 
 static void parse_device_name(AVFormatContext *s)
@@ -343,65 +294,51 @@ static int configure_video_device(AVFormatContext *s, AVCaptureDevice *video_dev
     NSObject *selected_range = nil;
     NSObject *selected_format = nil;
 
-    // try to configure format by formats list
-    // might raise an exception if no format list is given
-    // (then fallback to default, no configuration)
-    @try {
-        for (format in [video_device valueForKey:@"formats"]) {
-            CMFormatDescriptionRef formatDescription;
-            CMVideoDimensions dimensions;
+    for (format in [video_device valueForKey:@"formats"]) {
+        CMFormatDescriptionRef formatDescription;
+        CMVideoDimensions dimensions;
 
-            formatDescription = (CMFormatDescriptionRef) [format performSelector:@selector(formatDescription)];
-            dimensions = CMVideoFormatDescriptionGetDimensions(formatDescription);
+        formatDescription = (CMFormatDescriptionRef) [format performSelector:@selector(formatDescription)];
+        dimensions = CMVideoFormatDescriptionGetDimensions(formatDescription);
 
-            if ((ctx->width == 0 && ctx->height == 0) ||
-                (dimensions.width == ctx->width && dimensions.height == ctx->height)) {
+        if ((ctx->width == 0 && ctx->height == 0) ||
+            (dimensions.width == ctx->width && dimensions.height == ctx->height)) {
 
-                selected_format = format;
+            selected_format = format;
 
-                for (range in [format valueForKey:@"videoSupportedFrameRateRanges"]) {
-                    double max_framerate;
+            for (range in [format valueForKey:@"videoSupportedFrameRateRanges"]) {
+                double max_framerate;
 
-                    [[range valueForKey:@"maxFrameRate"] getValue:&max_framerate];
-                    if (fabs (framerate - max_framerate) < 0.01) {
-                        selected_range = range;
-                        break;
-                    }
+                [[range valueForKey:@"maxFrameRate"] getValue:&max_framerate];
+                if (fabs (framerate - max_framerate) < 0.01) {
+                    selected_range = range;
+                    break;
                 }
             }
         }
+    }
 
-        if (!selected_format) {
-            av_log(s, AV_LOG_ERROR, "Selected video size (%dx%d) is not supported by the device.\n",
-                ctx->width, ctx->height);
-            goto unsupported_format;
-        }
+    if (!selected_format) {
+        av_log(s, AV_LOG_ERROR, "Selected video size (%dx%d) is not supported by the device.\n",
+            ctx->width, ctx->height);
+        goto unsupported_format;
+    }
 
-        if (!selected_range) {
-            av_log(s, AV_LOG_ERROR, "Selected framerate (%f) is not supported by the device.\n",
-                framerate);
-            if (ctx->video_is_muxed) {
-                av_log(s, AV_LOG_ERROR, "Falling back to default.\n");
-            } else {
-                goto unsupported_format;
-            }
-        }
+    if (!selected_range) {
+        av_log(s, AV_LOG_ERROR, "Selected framerate (%f) is not supported by the device.\n",
+            framerate);
+        goto unsupported_format;
+    }
 
-        if ([video_device lockForConfiguration:NULL] == YES) {
-            if (selected_format) {
-                [video_device setValue:selected_format forKey:@"activeFormat"];
-            }
-            if (selected_range) {
-                NSValue *min_frame_duration = [selected_range valueForKey:@"minFrameDuration"];
-                [video_device setValue:min_frame_duration forKey:@"activeVideoMinFrameDuration"];
-                [video_device setValue:min_frame_duration forKey:@"activeVideoMaxFrameDuration"];
-            }
-        } else {
-            av_log(s, AV_LOG_ERROR, "Could not lock device for configuration.\n");
-            return AVERROR(EINVAL);
-        }
-    } @catch(NSException *e) {
-        av_log(ctx, AV_LOG_WARNING, "Configuration of video device failed, falling back to default.\n");
+    if ([video_device lockForConfiguration:NULL] == YES) {
+        NSValue *min_frame_duration = [selected_range valueForKey:@"minFrameDuration"];
+
+        [video_device setValue:selected_format forKey:@"activeFormat"];
+        [video_device setValue:min_frame_duration forKey:@"activeVideoMinFrameDuration"];
+        [video_device setValue:min_frame_duration forKey:@"activeVideoMaxFrameDuration"];
+    } else {
+        av_log(s, AV_LOG_ERROR, "Could not lock device for configuration.\n");
+        return AVERROR(EINVAL);
     }
 
     return 0;
@@ -534,32 +471,13 @@ static int add_video_device(AVFormatContext *s, AVCaptureDevice *video_device)
         }
     }
 
-    // set videoSettings to an empty dict for receiving raw data of muxed devices
-    if (ctx->capture_raw_data) {
-        ctx->pixel_format = pxl_fmt_spec.ff_id;
-        ctx->video_output.videoSettings = @{ };
-    } else {
-        ctx->pixel_format = pxl_fmt_spec.ff_id;
-        pixel_format = [NSNumber numberWithUnsignedInt:pxl_fmt_spec.avf_id];
-        capture_dict = [NSDictionary dictionaryWithObject:pixel_format
-                                                   forKey:(id)kCVPixelBufferPixelFormatTypeKey];
-
-        [ctx->video_output setVideoSettings:capture_dict];
-    }
-    [ctx->video_output setAlwaysDiscardsLateVideoFrames:ctx->drop_late_frames];
+    ctx->pixel_format          = pxl_fmt_spec.ff_id;
+    pixel_format = [NSNumber numberWithUnsignedInt:pxl_fmt_spec.avf_id];
+    capture_dict = [NSDictionary dictionaryWithObject:pixel_format
+                                               forKey:(id)kCVPixelBufferPixelFormatTypeKey];
 
-#if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
-    // check for transport control support and set observer device if supported
-    if (!ctx->video_is_screen) {
-        int trans_ctrl = [video_device transportControlsSupported];
-        AVCaptureDeviceTransportControlsPlaybackMode trans_mode = [video_device transportControlsPlaybackMode];
-
-        if (trans_ctrl) {
-            ctx->observed_mode   = trans_mode;
-            ctx->observed_device = video_device;
-        }
-    }
-#endif
+    [ctx->video_output setVideoSettings:capture_dict];
+    [ctx->video_output setAlwaysDiscardsLateVideoFrames:YES];
 
     ctx->avf_delegate = [[AVFFrameReceiver alloc] initWithContext:ctx];
 
@@ -624,8 +542,8 @@ static int add_audio_device(AVFormatContext *s, AVCaptureDevice *audio_device)
 static int get_video_config(AVFormatContext *s)
 {
     AVFContext *ctx = (AVFContext*)s->priv_data;
+    CMSampleBufferRef sample_buffer;
     CVImageBufferRef image_buffer;
-    CMBlockBufferRef block_buffer;
     CGSize image_buffer_size;
     AVStream* stream = avformat_new_stream(s, NULL);
 
@@ -638,33 +556,25 @@ static int get_video_config(AVFormatContext *s)
         CFRunLoopRunInMode(kCFRunLoopDefaultMode, 0.1, YES);
     }
 
-    lock_frames(ctx);
+    [ctx->lock lock];
 
     ctx->video_stream_index = stream->index;
 
     avpriv_set_pts_info(stream, 64, 1, avf_time_base);
 
-    image_buffer = CMSampleBufferGetImageBuffer(ctx->current_frame);
-    block_buffer = CMSampleBufferGetDataBuffer(ctx->current_frame);
-
-    if (image_buffer) {
-        image_buffer_size = CVImageBufferGetEncodedSize(image_buffer);
+    sample_buffer     = (CMSampleBufferRef)[ctx->video_queue lastObject];
+    image_buffer      = CMSampleBufferGetImageBuffer(sample_buffer);
+    image_buffer_size = CVImageBufferGetEncodedSize(image_buffer);
 
-        stream->codecpar->codec_id   = AV_CODEC_ID_RAWVIDEO;
-        stream->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;
-        stream->codecpar->width      = (int)image_buffer_size.width;
-        stream->codecpar->height     = (int)image_buffer_size.height;
-        stream->codecpar->format     = ctx->pixel_format;
-    } else {
-        stream->codecpar->codec_id   = AV_CODEC_ID_DVVIDEO;
-        stream->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;
-        stream->codecpar->format     = ctx->pixel_format;
-    }
+    stream->codecpar->codec_id   = AV_CODEC_ID_RAWVIDEO;
+    stream->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;
+    stream->codecpar->width      = (int)image_buffer_size.width;
+    stream->codecpar->height     = (int)image_buffer_size.height;
+    stream->codecpar->format     = ctx->pixel_format;
 
-    CFRelease(ctx->current_frame);
-    ctx->current_frame = nil;
+    [ctx->lock unlockWithCondition:QUEUE_HAS_BUFFERS];
 
-    unlock_frames(ctx);
+    [ctx->video_queue removeLastObject];
 
     return 0;
 }
@@ -672,6 +582,7 @@ static int get_video_config(AVFormatContext *s)
 static int get_audio_config(AVFormatContext *s)
 {
     AVFContext *ctx = (AVFContext*)s->priv_data;
+    CMSampleBufferRef sample_buffer;
     CMFormatDescriptionRef format_desc;
     AVStream* stream = avformat_new_stream(s, NULL);
 
@@ -684,13 +595,14 @@ static int get_audio_config(AVFormatContext *s)
         CFRunLoopRunInMode(kCFRunLoopDefaultMode, 0.1, YES);
     }
 
-    lock_frames(ctx);
+    [ctx->lock lock];
 
     ctx->audio_stream_index = stream->index;
 
     avpriv_set_pts_info(stream, 64, 1, avf_time_base);
 
-    format_desc = CMSampleBufferGetFormatDescription(ctx->current_audio_frame);
+    sample_buffer = (CMSampleBufferRef)[ctx->audio_queue lastObject];
+    format_desc = CMSampleBufferGetFormatDescription(sample_buffer);
     const AudioStreamBasicDescription *basic_desc = CMAudioFormatDescriptionGetStreamBasicDescription(format_desc);
 
     if (!basic_desc) {
@@ -737,7 +649,7 @@ static int get_audio_config(AVFormatContext *s)
     }
 
     if (ctx->audio_non_interleaved) {
-        CMBlockBufferRef block_buffer = CMSampleBufferGetDataBuffer(ctx->current_audio_frame);
+        CMBlockBufferRef block_buffer = CMSampleBufferGetDataBuffer(sample_buffer);
         ctx->audio_buffer_size        = CMBlockBufferGetDataLength(block_buffer);
         ctx->audio_buffer             = av_malloc(ctx->audio_buffer_size);
         if (!ctx->audio_buffer) {
@@ -746,10 +658,7 @@ static int get_audio_config(AVFormatContext *s)
         }
     }
 
-    CFRelease(ctx->current_audio_frame);
-    ctx->current_audio_frame = nil;
-
-    unlock_frames(ctx);
+    [ctx->lock unlockWithCondition:QUEUE_HAS_BUFFERS];
 
     return 0;
 }
@@ -757,19 +666,21 @@ static int get_audio_config(AVFormatContext *s)
 static int avf_read_header(AVFormatContext *s)
 {
     NSAutoreleasePool *pool = [[NSAutoreleasePool alloc] init];
+    int capture_screen      = 0;
     uint32_t num_screens    = 0;
     AVFContext *ctx         = (AVFContext*)s->priv_data;
     AVCaptureDevice *video_device = nil;
     AVCaptureDevice *audio_device = nil;
     // Find capture device
     NSArray *devices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];
-    NSArray *devices_muxed = [AVCaptureDevice devicesWithMediaType:AVMediaTypeMuxed];
+    ctx->num_video_devices = [devices count];
 
-    ctx->num_video_devices = [devices count] + [devices_muxed count];
     ctx->first_pts          = av_gettime();
     ctx->first_audio_pts    = av_gettime();
 
-    pthread_mutex_init(&ctx->frame_lock, NULL);
+    ctx->lock = [[NSConditionLock alloc] initWithCondition:QUEUE_IS_EMPTY];
+    ctx->video_queue = [[NSMutableArray alloc] initWithCapacity:QUEUE_SIZE];
+    ctx->audio_queue = [[NSMutableArray alloc] initWithCapacity:QUEUE_SIZE];
 
 #if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
     CGGetActiveDisplayList(0, NULL, &num_screens);
@@ -784,17 +695,12 @@ static int avf_read_header(AVFormatContext *s)
             index            = [devices indexOfObject:device];
             av_log(ctx, AV_LOG_INFO, "[%d] %s\n", index, name);
         }
-        for (AVCaptureDevice *device in devices_muxed) {
-            const char *name = [[device localizedName] UTF8String];
-            index            = [devices count] + [devices_muxed indexOfObject:device];
-            av_log(ctx, AV_LOG_INFO, "[%d] %s\n", index, name);
-        }
 #if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
         if (num_screens > 0) {
             CGDirectDisplayID screens[num_screens];
             CGGetActiveDisplayList(num_screens, screens, &num_screens);
             for (int i = 0; i < num_screens; i++) {
-                av_log(ctx, AV_LOG_INFO, "[%d] Capture screen %d\n", ctx->num_video_devices + i, i);
+                av_log(ctx, AV_LOG_INFO, "[%d] Capture screen %d\n", index + i, i);
             }
         }
 #endif
@@ -822,12 +728,7 @@ static int avf_read_header(AVFormatContext *s)
 
     if (ctx->video_device_index >= 0) {
         if (ctx->video_device_index < ctx->num_video_devices) {
-            if (ctx->video_device_index < [devices count]) {
-                video_device = [devices objectAtIndex:ctx->video_device_index];
-            } else {
-                video_device = [devices_muxed objectAtIndex:(ctx->video_device_index - [devices count])];
-                ctx->video_is_muxed = 1;
-            }
+            video_device = [devices objectAtIndex:ctx->video_device_index];
         } else if (ctx->video_device_index < ctx->num_video_devices + num_screens) {
 #if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
             CGDirectDisplayID screens[num_screens];
@@ -853,7 +754,7 @@ static int avf_read_header(AVFormatContext *s)
             }
 
             video_device = (AVCaptureDevice*) capture_screen_input;
-            ctx->video_is_screen = 1;
+            capture_screen = 1;
 #endif
          } else {
             av_log(ctx, AV_LOG_ERROR, "Invalid device index\n");
@@ -871,14 +772,6 @@ static int avf_read_header(AVFormatContext *s)
                 break;
             }
         }
-        // looking for muxed inputs
-        for (AVCaptureDevice *device in devices_muxed) {
-            if (!strncmp(ctx->video_filename, [[device localizedName] UTF8String], strlen(ctx->video_filename))) {
-                video_device = device;
-                ctx->video_is_muxed = 1;
-                break;
-            }
-        }
 
 #if !TARGET_OS_IPHONE && __MAC_OS_X_VERSION_MIN_REQUIRED >= 1070
         // looking for screen inputs
@@ -890,7 +783,7 @@ static int avf_read_header(AVFormatContext *s)
                 AVCaptureScreenInput* capture_screen_input = [[[AVCaptureScreenInput alloc] initWithDisplayID:screens[idx]] autorelease];
                 video_device = (AVCaptureDevice*) capture_screen_input;
                 ctx->video_device_index = ctx->num_video_devices + idx;
-                ctx->video_is_screen = 1;
+                capture_screen = 1;
 
                 if (ctx->framerate.num > 0) {
                     capture_screen_input.minFrameDuration = CMTimeMake(ctx->framerate.den, ctx->framerate.num);
@@ -981,7 +874,7 @@ static int avf_read_header(AVFormatContext *s)
 
     /* Unlock device configuration only after the session is started so it
      * does not reset the capture formats */
-    if (!ctx->video_is_screen) {
+    if (!capture_screen) {
         [video_device unlockForConfiguration];
     }
 
@@ -1051,33 +944,48 @@ static int avf_read_packet(AVFormatContext *s, AVPacket *pkt)
     AVFContext* ctx = (AVFContext*)s->priv_data;
 
     do {
-        CVImageBufferRef image_buffer;
-        CMBlockBufferRef block_buffer;
-        lock_frames(ctx);
-
-        if (ctx->current_frame != nil) {
-            int status;
-            int length = 0;
-
-            image_buffer = CMSampleBufferGetImageBuffer(ctx->current_frame);
-            block_buffer = CMSampleBufferGetDataBuffer(ctx->current_frame);
-
-            if (image_buffer != nil) {
-                length = (int)CVPixelBufferGetDataSize(image_buffer);
-            } else if (block_buffer != nil) {
-                length = (int)CMBlockBufferGetDataLength(block_buffer);
-            } else  {
-                return AVERROR(EINVAL);
-            }
+        int got_buffer = 0;
+        CMSampleBufferRef asample_buffer;
+        CMSampleBufferRef vsample_buffer;
+
+        [ctx->lock lockWhenCondition:QUEUE_HAS_BUFFERS];
+        vsample_buffer = (CMSampleBufferRef)[ctx->video_queue lastObject];
+        if (vsample_buffer) {
+            vsample_buffer = (CMSampleBufferRef)CFRetain(vsample_buffer);
+            [ctx->video_queue removeLastObject];
+
+            got_buffer |= 1;
+        }
+
+        asample_buffer = (CMSampleBufferRef)[ctx->audio_queue lastObject];
+        if (asample_buffer) {
+            asample_buffer = (CMSampleBufferRef)CFRetain(asample_buffer);
+            [ctx->audio_queue removeLastObject];
+
+            got_buffer |= 1;
+        }
+
+        if (!got_buffer || ([ctx->video_queue count] == 0 && [ctx->audio_queue count] == 0)) {
+            [ctx->lock unlockWithCondition:QUEUE_IS_EMPTY];
+        } else {
+            [ctx->lock unlock];
+        }
+
+        if (vsample_buffer != nil) {
+            void *data;
+            CVImageBufferRef image_buffer;
 
-            if (av_new_packet(pkt, length) < 0) {
+            image_buffer = CMSampleBufferGetImageBuffer(vsample_buffer);
+            if (av_new_packet(pkt, (int)CVPixelBufferGetDataSize(image_buffer)) < 0) {
+                CVPixelBufferUnlockBaseAddress(image_buffer, 0);
+                CFRelease(vsample_buffer);
                 return AVERROR(EIO);
             }
 
             CMItemCount count;
             CMSampleTimingInfo timing_info;
 
-            if (CMSampleBufferGetOutputSampleTimingInfoArray(ctx->current_frame, 1, &timing_info, &count) == noErr) {
+            if (CMSampleBufferGetOutputSampleTimingInfoArray(vsample_buffer, 1, &timing_info, &count) == noErr) {
                 AVRational timebase_q = av_make_q(1, timing_info.presentationTimeStamp.timescale);
                 pkt->pts = pkt->dts = av_rescale_q(timing_info.presentationTimeStamp.value, timebase_q, avf_time_base_q);
             }
@@ -1085,22 +993,18 @@ static int avf_read_packet(AVFormatContext *s, AVPacket *pkt)
             pkt->stream_index  = ctx->video_stream_index;
             pkt->flags        |= AV_PKT_FLAG_KEY;
 
-            if (image_buffer) {
-                status = copy_cvpixelbuffer(s, image_buffer, pkt);
-            } else {
-                status = 0;
-                OSStatus ret = CMBlockBufferCopyDataBytes(block_buffer, 0, pkt->size, pkt->data);
-                if (ret != kCMBlockBufferNoErr) {
-                    status = AVERROR(EIO);
-                }
-             }
-            CFRelease(ctx->current_frame);
-            ctx->current_frame = nil;
-
-            if (status < 0)
-                return status;
-        } else if (ctx->current_audio_frame != nil) {
-            CMBlockBufferRef block_buffer = CMSampleBufferGetDataBuffer(ctx->current_audio_frame);
+            CVPixelBufferLockBaseAddress(image_buffer, 0);
+
+            data = CVPixelBufferGetBaseAddress(image_buffer);
+            memcpy(pkt->data, data, pkt->size);
+
+            CVPixelBufferUnlockBaseAddress(image_buffer, 0);
+            CFRelease(vsample_buffer);
+            vsample_buffer = NULL;
+        }
+
+        if (asample_buffer != nil) {
+            CMBlockBufferRef block_buffer = CMSampleBufferGetDataBuffer(asample_buffer);
             int block_buffer_size         = CMBlockBufferGetDataLength(block_buffer);
 
             if (!block_buffer || !block_buffer_size) {
@@ -1118,7 +1022,7 @@ static int avf_read_packet(AVFormatContext *s, AVPacket *pkt)
             CMItemCount count;
             CMSampleTimingInfo timing_info;
 
-            if (CMSampleBufferGetOutputSampleTimingInfoArray(ctx->current_audio_frame, 1, &timing_info, &count) == noErr) {
+            if (CMSampleBufferGetOutputSampleTimingInfoArray(asample_buffer, 1, &timing_info, &count) == noErr) {
                 AVRational timebase_q = av_make_q(1, timing_info.presentationTimeStamp.timescale);
                 pkt->pts = pkt->dts = av_rescale_q(timing_info.presentationTimeStamp.value, timebase_q, avf_time_base_q);
             }
@@ -1166,19 +1070,9 @@ static int avf_read_packet(AVFormatContext *s, AVPacket *pkt)
                 }
             }
 
-            CFRelease(ctx->current_audio_frame);
-            ctx->current_audio_frame = nil;
-        } else {
-            pkt->data = NULL;
-            unlock_frames(ctx);
-            if (ctx->observed_quit) {
-                return AVERROR_EOF;
-            } else {
-                return AVERROR(EAGAIN);
-            }
+            CFRelease(asample_buffer);
+            asample_buffer = NULL;
         }
-
-        unlock_frames(ctx);
     } while (!pkt->data);
 
     return 0;
@@ -1200,8 +1094,6 @@ static const AVOption options[] = {
     { "video_size", "set video size", offsetof(AVFContext, width), AV_OPT_TYPE_IMAGE_SIZE, {.str = NULL}, 0, 0, AV_OPT_FLAG_DECODING_PARAM },
     { "capture_cursor", "capture the screen cursor", offsetof(AVFContext, capture_cursor), AV_OPT_TYPE_BOOL, {.i64=0}, 0, 1, AV_OPT_FLAG_DECODING_PARAM },
     { "capture_mouse_clicks", "capture the screen mouse clicks", offsetof(AVFContext, capture_mouse_clicks), AV_OPT_TYPE_BOOL, {.i64=0}, 0, 1, AV_OPT_FLAG_DECODING_PARAM },
-    { "capture_raw_data", "capture the raw data from device connection", offsetof(AVFContext, capture_raw_data), AV_OPT_TYPE_BOOL, {.i64=0}, 0, 1, AV_OPT_FLAG_DECODING_PARAM },
-    { "drop_late_frames", "drop frames that are available later than expected", offsetof(AVFContext, drop_late_frames), AV_OPT_TYPE_BOOL, {.i64=1}, 0, 1, AV_OPT_FLAG_DECODING_PARAM },
 
     { NULL },
 };
